{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ChatBot_Project"
      ],
      "metadata": {
        "id": "e9FYkkkQnz50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Kpwt7NVboaQH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "punkt is a pre-trained model included in the Natural Language Toolkit (nltk) that is used for tokenization. Tokenization is the process of splitting text into individual units, such as words or sentences"
      ],
      "metadata": {
        "id": "J2cHwyi_s73r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cuJZj8c8s5Uo",
        "outputId": "cde7e619-1a86-43f7-bc36-44c072e76a98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "wordnet is used to download the WordNet corpus, which is necessary for performing lemmatization with NLTK's"
      ],
      "metadata": {
        "id": "K2vKQPhFvNkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TudAn7-dvXLS",
        "outputId": "5fecb947-3231-4477-f2f7-fc42d64036f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "VoxmanIsqmbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_letters = ['?', '!', '.', ',']\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "a6oAPCWzp9Z2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = open('intents.json').read()\n",
        "intents = json.loads(data_file)"
      ],
      "metadata": {
        "id": "Y5QRprdlOWkC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        word_list = nltk.word_tokenize(pattern)\n",
        "        words.extend(word_list)\n",
        "        documents.append((word_list, intent['tag']))\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ],
      "metadata": {
        "id": "DYBjHjExsaWg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [lemmatizer.lemmatize(word) for word in words if word not in ignore_letters]\n",
        "words = sorted(list(set(words)))\n",
        "classes = sorted(list(set(classes)))\n"
      ],
      "metadata": {
        "id": "AwQxz-BEssVt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(documents), \"documents\")\n",
        "print(len(classes), \"classes\", classes)\n",
        "print(len(words), \"unique lemmatized words\", words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-VplGvYR9Mh",
        "outputId": "f78e63ba-fe72-446a-8a41-66835393ec85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34 documents\n",
            "8 classes ['about', 'chatbot', 'connect', 'goodbye', 'greeting', 'location', 'movies', 'thanks']\n",
            "68 unique lemmatized words [\"'s\", 'Awesome', 'Bye', 'Chatbot', 'Give', 'Good', 'Goodbye', 'Hello', 'Hey', 'Hi', 'Hola', 'How', 'Is', 'Nice', 'Recommend', 'See', 'Suggest', 'Tell', 'Thank', 'Thanks', 'That', 'Till', 'What', 'Where', 'Which', 'Who', 'Yourself', 'about', 'account', 'address', 'any', 'anyone', 'are', 'built', 'bye', 'can', 'chatbot', 'chatting', 'connect', 'day', 'favourite', 'for', 'helpful', 'helping', 'i', 'is', 'later', 'link', 'located', 'location', 'me', 'medium', 'movie', 'name', 'next', 'out', 'reach', 'social', 'some', 'thanks', 'there', 'this', 'time', 'to', 'way', 'we', 'you', 'your']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Data"
      ],
      "metadata": {
        "id": "4xfkLhrMvqhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training = []\n",
        "empty_array = [0] * len(classes)"
      ],
      "metadata": {
        "id": "eE0YgB4_vpgq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for document in documents:\n",
        "    bag = []\n",
        "    word_patterns = document[0]\n",
        "    word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
        "    for word in words:\n",
        "        bag.append(1) if word in word_patterns else bag.append(0)\n",
        "    output_row = list(empty_array)\n",
        "    output_row[classes.index(document[1])] = 1\n",
        "    training.append([bag, output_row])"
      ],
      "metadata": {
        "id": "2bWbunGdvHCm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(training)\n",
        "trainings = np.array(training, dtype=object)"
      ],
      "metadata": {
        "id": "Bhp9OdVCwtWA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "train_x, test_x, train_y, test_y = train_test_split(list(trainings[:, 0]), list(trainings[:, 1]), test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "A-QuXpJ8L5nw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model creating"
      ],
      "metadata": {
        "id": "OYJOcjO5ySGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))"
      ],
      "metadata": {
        "id": "rBeU4HvxzsXW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=150, batch_size=5, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DwPJguUU0pSO",
        "outputId": "cc534584-c133-4343-e918-7bd0d9127676"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "6/6 [==============================] - 1s 4ms/step - loss: 2.0885 - accuracy: 0.1481\n",
            "Epoch 2/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 2.0598 - accuracy: 0.2593\n",
            "Epoch 3/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.9989 - accuracy: 0.3333\n",
            "Epoch 4/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 2.0308 - accuracy: 0.2963\n",
            "Epoch 5/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.9685 - accuracy: 0.3704\n",
            "Epoch 6/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.9374 - accuracy: 0.3333\n",
            "Epoch 7/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.8552 - accuracy: 0.3333\n",
            "Epoch 8/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 1.8643 - accuracy: 0.4815\n",
            "Epoch 9/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.8159 - accuracy: 0.3333\n",
            "Epoch 10/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.7517 - accuracy: 0.4815\n",
            "Epoch 11/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.6701 - accuracy: 0.5926\n",
            "Epoch 12/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.7286 - accuracy: 0.4815\n",
            "Epoch 13/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.5133 - accuracy: 0.6296\n",
            "Epoch 14/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.4258 - accuracy: 0.6296\n",
            "Epoch 15/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.4114 - accuracy: 0.5556\n",
            "Epoch 16/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 1.4188 - accuracy: 0.5185\n",
            "Epoch 17/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.4406 - accuracy: 0.4074\n",
            "Epoch 18/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 1.2919 - accuracy: 0.7778\n",
            "Epoch 19/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 1.2142 - accuracy: 0.7037\n",
            "Epoch 20/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.2695 - accuracy: 0.6667\n",
            "Epoch 21/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 1.1574 - accuracy: 0.6667\n",
            "Epoch 22/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.9327 - accuracy: 0.7778\n",
            "Epoch 23/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.0322 - accuracy: 0.7778\n",
            "Epoch 24/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.9944 - accuracy: 0.7407\n",
            "Epoch 25/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.1293 - accuracy: 0.7407\n",
            "Epoch 26/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.0366 - accuracy: 0.6296\n",
            "Epoch 27/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8030 - accuracy: 0.8148\n",
            "Epoch 28/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8380 - accuracy: 0.7407\n",
            "Epoch 29/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.8519\n",
            "Epoch 30/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7829 - accuracy: 0.7407\n",
            "Epoch 31/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.9396 - accuracy: 0.5926\n",
            "Epoch 32/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8800 - accuracy: 0.7037\n",
            "Epoch 33/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7750 - accuracy: 0.7778\n",
            "Epoch 34/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.8148\n",
            "Epoch 35/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.8889\n",
            "Epoch 36/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.8889\n",
            "Epoch 37/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.8148\n",
            "Epoch 38/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.7778\n",
            "Epoch 39/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.9259\n",
            "Epoch 40/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.8889\n",
            "Epoch 41/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.8148\n",
            "Epoch 42/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8889\n",
            "Epoch 43/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.8148\n",
            "Epoch 44/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.8889\n",
            "Epoch 45/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.9259\n",
            "Epoch 46/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.8148\n",
            "Epoch 47/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8148\n",
            "Epoch 48/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.9259\n",
            "Epoch 49/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.9630\n",
            "Epoch 50/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.8889\n",
            "Epoch 51/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8889\n",
            "Epoch 52/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.9630\n",
            "Epoch 53/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3064 - accuracy: 0.9259\n",
            "Epoch 54/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8519\n",
            "Epoch 55/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.9259\n",
            "Epoch 56/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8148\n",
            "Epoch 57/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.8148\n",
            "Epoch 58/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9630\n",
            "Epoch 59/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8519\n",
            "Epoch 60/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.8889\n",
            "Epoch 61/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.8889\n",
            "Epoch 62/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8889\n",
            "Epoch 63/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8889\n",
            "Epoch 64/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8889\n",
            "Epoch 65/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8519\n",
            "Epoch 66/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.9259\n",
            "Epoch 67/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8519\n",
            "Epoch 68/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.2385 - accuracy: 0.8889\n",
            "Epoch 69/150\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.3070 - accuracy: 0.8889\n",
            "Epoch 70/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.8889\n",
            "Epoch 71/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2386 - accuracy: 0.9259\n",
            "Epoch 72/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.9259\n",
            "Epoch 73/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.9259\n",
            "Epoch 74/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9630\n",
            "Epoch 75/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9259\n",
            "Epoch 76/150\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9630\n",
            "Epoch 77/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8889\n",
            "Epoch 78/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 1.0000\n",
            "Epoch 79/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8889\n",
            "Epoch 80/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1947 - accuracy: 0.9259\n",
            "Epoch 81/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9259\n",
            "Epoch 82/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9630\n",
            "Epoch 83/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8519\n",
            "Epoch 84/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9630\n",
            "Epoch 85/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9630\n",
            "Epoch 86/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9630\n",
            "Epoch 87/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.2424 - accuracy: 0.9259\n",
            "Epoch 88/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9630\n",
            "Epoch 89/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9630\n",
            "Epoch 90/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0975 - accuracy: 1.0000\n",
            "Epoch 91/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 1.0000\n",
            "Epoch 92/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 1.0000\n",
            "Epoch 93/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 1.0000\n",
            "Epoch 94/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.8889\n",
            "Epoch 95/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9259\n",
            "Epoch 96/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.8148\n",
            "Epoch 97/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9259\n",
            "Epoch 98/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 1.0000\n",
            "Epoch 99/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9630\n",
            "Epoch 100/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.8889\n",
            "Epoch 101/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9259\n",
            "Epoch 102/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1355 - accuracy: 0.9630\n",
            "Epoch 103/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9259\n",
            "Epoch 104/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9259\n",
            "Epoch 105/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.9630\n",
            "Epoch 106/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9630\n",
            "Epoch 107/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2292 - accuracy: 0.8889\n",
            "Epoch 108/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9259\n",
            "Epoch 109/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9630\n",
            "Epoch 110/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9630\n",
            "Epoch 111/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1641 - accuracy: 0.9259\n",
            "Epoch 112/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9259\n",
            "Epoch 113/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1232 - accuracy: 1.0000\n",
            "Epoch 114/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9259\n",
            "Epoch 115/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9630\n",
            "Epoch 116/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9630\n",
            "Epoch 117/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.8889\n",
            "Epoch 118/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9259\n",
            "Epoch 119/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9259\n",
            "Epoch 120/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9259\n",
            "Epoch 121/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0980 - accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9630\n",
            "Epoch 124/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2309 - accuracy: 0.9259\n",
            "Epoch 125/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9630\n",
            "Epoch 126/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.9259\n",
            "Epoch 127/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9259\n",
            "Epoch 128/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9630\n",
            "Epoch 129/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9630\n",
            "Epoch 130/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1817 - accuracy: 0.9259\n",
            "Epoch 131/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9630\n",
            "Epoch 132/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.9259\n",
            "Epoch 133/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.9259\n",
            "Epoch 134/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9259\n",
            "Epoch 135/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9630\n",
            "Epoch 136/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9259\n",
            "Epoch 137/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1229 - accuracy: 0.9630\n",
            "Epoch 138/150\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9630\n",
            "Epoch 139/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0981 - accuracy: 0.9630\n",
            "Epoch 141/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9259\n",
            "Epoch 143/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.8519\n",
            "Epoch 144/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9630\n",
            "Epoch 145/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9630\n",
            "Epoch 146/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9259\n",
            "Epoch 147/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9630\n",
            "Epoch 148/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9259\n",
            "Epoch 149/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9630\n",
            "Epoch 150/150\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.8889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#END"
      ],
      "metadata": {
        "id": "kbWha9nX2vQz"
      }
    }
  ]
}